{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Необработанный формат ячейки",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "KK_HW_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfDmuCsL60RB"
      },
      "source": [
        "**Import Functions and Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He0f8AOQ60RE"
      },
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from os import getcwd\n",
        "from nltk.corpus import twitter_samples\n",
        "from utils import process_tweet, build_freqs"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TpOiR3BZ60RH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032b87a2-18a5-407f-9380-95480ec54eb1"
      },
      "source": [
        "nltk.download ('twitter_samples')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0k_mIOZ60RJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bd6014-05be-4f1b-d004-46c07a023da1"
      },
      "source": [
        "nltk.download ('stopwords')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oqbjzOI60RK"
      },
      "source": [
        "filePath = f\"{getcwd()}/../tmp2/\"\n",
        "nltk.data.path.append(filePath)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8b--Aa60RL"
      },
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3bcbYgR60RM"
      },
      "source": [
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg \n",
        "test_x = test_pos + test_neg"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbucXSNj60RN"
      },
      "source": [
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jERTLsRF60RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03eb6f8-dc84-4cd6-ef7f-002592b69725"
      },
      "source": [
        "print(\"train_y.shape = \" + str(train_y.shape))\n",
        "print(\"test_y.shape = \" + str(test_y.shape))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_y.shape = (8000, 1)\n",
            "test_y.shape = (2000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGh5qcWa60RP"
      },
      "source": [
        "freqs = build_freqs(train_x, train_y)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZgpNNYe60RP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4116cb-0ba1-42dd-bc28-839fb59e2ccc"
      },
      "source": [
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(freqs) = <class 'dict'>\n",
            "len(freqs) = 11346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIfLM6C-60RQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75a3781-9b05-44e5-ccd4-fc9bc9de6adb"
      },
      "source": [
        "print('This is an example of a positive tweet: \\n', train_x[0])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an example of a positive tweet: \n",
            " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "\n",
            "This is an example of the processed version of the tweet: \n",
            " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2zLvHwl60RR"
      },
      "source": [
        "**1: Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La-ZYLjY60RR"
      },
      "source": [
        "**1.1: Sigmoid**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vocXKA_p60RS"
      },
      "source": [
        "def sigmoid(z):\n",
        "    h = 1/(1+np.exp(-z))\n",
        "    return h"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79U49HCA60RS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d98b373-15ac-4835-f36c-3469bcb14f06"
      },
      "source": [
        "if (sigmoid(0) == 0.5):\n",
        "    print('SUCCESS!')\n",
        "else:\n",
        "    print('Oops!')\n",
        "\n",
        "if (sigmoid(4.92) == 0.9927537604041685):\n",
        "    print('CORRECT!')\n",
        "else:\n",
        "    print('Oops again!')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS!\n",
            "CORRECT!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuG_LNN460RS"
      },
      "source": [
        "**1.2: Cost Function and Gradient**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgMI46-o60RT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a91e1cb-7d70-4451-cc7b-bb63af0d55a9"
      },
      "source": [
        "-1 * (1 - 0) * np.log(1 - 0.9999)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.210340371976294"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGAE_s9360RT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdfa97d-1de1-4a2c-9022-1a27843b2e93"
      },
      "source": [
        "-1 * np.log(0.0001)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.210340371976182"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YomvSYuT60RU"
      },
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    m = x.shape[0]\n",
        "    for i in range(0, num_iters):\n",
        "        z = np.dot(x, theta)\n",
        "        h = sigmoid(z)\n",
        "        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))\n",
        "        theta = theta - (alpha/m)*(np.dot(np.transpose(x),(h-y)))\n",
        "    J = np.float(J)\n",
        "    return J, theta"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fTZxk-l60RU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53d4373-7085-4b24-9599-ca4b3eb4904f"
      },
      "source": [
        "np.random.seed(1)\n",
        "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
        "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
        "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
        "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost after training is 0.67094970.\n",
            "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq53awZs60RV"
      },
      "source": [
        "**2: Extracting the Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HVUVNcv60RV"
      },
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    word_l = process_tweet(tweet)\n",
        "    x = np.zeros((1, 3))\n",
        "    x[0,0] = 1 \n",
        "    for word in word_l:\n",
        "        if (word,1.0) in freqs:\n",
        "            x[0,1] += freqs.get((word,1.0),0)\n",
        "        if (word,0.0) in freqs:\n",
        "            x[0,2] += freqs.get((word,0.0),0)\n",
        "    assert(x.shape == (1, 3))\n",
        "    return x"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WrRDkb660RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df971b1-5d7e-4826-f107-d67a985f1ddd"
      },
      "source": [
        "tmp1 = extract_features(train_x[0], freqs)\n",
        "print(tmp1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00e+00 3.02e+03 6.10e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7rRKOzz60RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11db8c73-0d2d-4516-b8de-b6bd8c6bb38f"
      },
      "source": [
        "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
        "print(tmp2)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQTyH1k460RW"
      },
      "source": [
        "**3: Training your Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md3WOFZr60RX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008c3a91-0e9a-48e1-903d-675953714049"
      },
      "source": [
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "Y = train_y\n",
        "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost after training is 0.24216529.\n",
            "The resulting vector of weights is [7e-08, 0.0005239, -0.00055517]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSzP-pDJ60RX"
      },
      "source": [
        "**4: Test your Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcpSciG_60RX"
      },
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "    x = extract_features(tweet, freqs)\n",
        "    y_pred = sigmoid(np.dot(x, theta))\n",
        "    return y_pred"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k26Ryk0t60RX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91be6ae9-5de6-481f-8c1e-bd95e9c69acd"
      },
      "source": [
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy -> 0.518580\n",
            "I am bad -> 0.494339\n",
            "this movie should have been great. -> 0.515331\n",
            "great -> 0.515464\n",
            "great great -> 0.530898\n",
            "great great great -> 0.546273\n",
            "great great great great -> 0.561561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ2VedOk60RY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7fd38a-5a94-45af-acb2-38c7725e5686"
      },
      "source": [
        "my_tweet = 'I love pasta :)'\n",
        "predict_tweet(my_tweet, freqs, theta)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.83137399]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jB5Tpxa60RY"
      },
      "source": [
        "**Check Performance Using the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu3lUNXD60RY"
      },
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "    y_hat = []\n",
        "    for tweet in test_x:\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "        if y_pred > 0.5:\n",
        "            y_hat.append(1)\n",
        "        else:\n",
        "            y_hat.append(0)\n",
        "    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n",
        "    return accuracy"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECHbd_YP60RY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f0b542-b29e-4260-9128-7055d8863259"
      },
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression model's accuracy = 0.9950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDP0LgXn60RY"
      },
      "source": [
        "**5: Error Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1rZfDXL60RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9e76b8-3832-440b-a135-6a00b8a5e0cd"
      },
      "source": [
        "print('Label Predicted Tweet')\n",
        "for x,y in zip(test_x,test_y):\n",
        "    y_hat = predict_tweet(x, freqs, theta)\n",
        "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
        "        print('THE TWEET IS:', x)\n",
        "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
        "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Predicted Tweet\n",
            "THE TWEET IS: @jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp\n",
            "THE PROCESSED TWEET IS: ['truli', 'later', 'move', 'know', 'queen', 'bee', 'upward', 'bound', 'movingonup']\n",
            "1\t0.49996890\tb'truli later move know queen bee upward bound movingonup'\n",
            "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
            "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
            "1\t0.48622857\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots\n",
            "http://t.co/UGQzOx0huu\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48370665\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48370665\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48370665\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: off to the park to get some sunlight : )\n",
            "THE PROCESSED TWEET IS: ['park', 'get', 'sunlight']\n",
            "1\t0.49578765\tb'park get sunlight'\n",
            "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
            "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
            "1\t0.48199810\tb'uff itna miss karhi thi ap :p'\n",
            "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
            "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
            "0\t0.50020353\tb'u prob fun david'\n",
            "THE TWEET IS: pats jay : (\n",
            "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
            "0\t0.50039294\tb'pat jay'\n",
            "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
            "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
            "0\t0.50000002\tb'belov grandmoth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0bnfJ1h60RZ"
      },
      "source": [
        "**6: Predict With your Own Tweet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNktYGfT60RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cfaf4c3-1f89-4619-d258-9515cd5c9be5"
      },
      "source": [
        "my_tweet = 'In this world just your smile can smooth my ride'\n",
        "print(process_tweet(my_tweet))\n",
        "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else: \n",
        "    print('Negative sentiment')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['world', 'smile', 'smooth', 'ride']\n",
            "[[0.50607541]]\n",
            "Positive sentiment\n"
          ]
        }
      ]
    }
  ]
}